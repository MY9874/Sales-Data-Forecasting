{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hi there, we are group 65. <br>\n",
    "To run the code, there are two things to be noticed: <br>\n",
    "1. Put all the .csv files into a folder named \"data\", this \"data\" folder should be in the same directory as this notebook file\n",
    "2. This code uses darts library, you may want to install it first. To install it, just uncomment the corresponding first few line of code in section 0 and run the cells <br>\n",
    "\n",
    "Wish you have a great holiday. <br>\n",
    "Cheers!\n",
    "\n",
    "# 0. Import Packages & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# !pip install lightgbm  # you may want to install the light gbm library if it is not available locally\n",
    "# !pip install darts  # you may want to install darts library if it is not available locally\n",
    "\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.models import LightGBMModel, MovingAverage\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import Scaler, StaticCovariatesTransformer, MissingValuesFiller, InvertibleMapper\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# change the setting so that there won't be warning during the feature engineering\n",
    "pd.options.mode.chained_assignment = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Preprocessing\n",
    "## 1.1 load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "oil_df = pd.read_csv('data/oil.csv')\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "holiday_df = pd.read_csv('data/holidays_events.csv')\n",
    "stores_df = pd.read_csv('data/stores.csv')\n",
    "trans_df = pd.read_csv('data/transactions.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 data cleaning / formatting\n",
    "### 1.2.1 oil data (past data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "# create timeseries for oil data\n",
    "oil_ts = TimeSeries.from_dataframe(oil_df,time_col = 'date',value_cols = ['dcoilwtico'],freq = 'D')\n",
    "\n",
    "# define a oil cleaning pipeline\n",
    "oil_pip = Pipeline([MissingValuesFiller(),Scaler()])\n",
    "\n",
    "# get cleaned oil data\n",
    "oil_ts = oil_pip.fit_transform(oil_ts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.2 sales and store data (past and static data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# join the training data and store data\n",
    "train_store_df = pd.merge(train_df, stores_df, on='store_nbr')\n",
    "\n",
    "# seperate data by families\n",
    "train_store_df.astype({'store_nbr':'str','cluster':'str'})\n",
    "train_ts_lst = TimeSeries.from_group_dataframe(train_store_df,time_col='date',value_cols='sales',group_cols=['store_nbr','family'],static_cols=['state','type','cluster','city'],fill_missing_dates=True,freq='D')\n",
    "families_dict = {}\n",
    "for ts in train_ts_lst:\n",
    "    if ts.static_covariates_values()[0,1] in families_dict:\n",
    "        families_dict[ts.static_covariates_values()[0,1]]['ts'].append(ts)\n",
    "    else:\n",
    "        families_dict[ts.static_covariates_values()[0,1]]= {'ts':[ts]}\n",
    "\n",
    "for family in families_dict.keys():\n",
    "    # define sales data cleaning pipeline\n",
    "    sales_pip = Pipeline([MissingValuesFiller(), InvertibleMapper(np.log1p,np.expm1), Scaler(), StaticCovariatesTransformer(transformer_cat=OneHotEncoder())])\n",
    "    families_dict[family]['ts'] = sales_pip.fit_transform(families_dict[family]['ts'])\n",
    "    families_dict[family]['pipe'] = sales_pip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.3 transaction data (past data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "trans_dict = {}\n",
    "trans_df = trans_df.drop([0]) # delete the first row which is dirty data\n",
    "\n",
    "trans_ts_lst = []\n",
    "for str_nbr in range(1,55):\n",
    "    tmp_trans_df = trans_df.loc[trans_df['store_nbr']==str_nbr]\n",
    "    cur_ts = TimeSeries.from_dataframe(tmp_trans_df,time_col='date',value_cols='transactions',fill_missing_dates=True,freq='D')\n",
    "    if cur_ts.start_time() != pd.to_datetime('2013-1-1'):\n",
    "        missing_days = (cur_ts.start_time()-pd.to_datetime('2013-1-1')).days\n",
    "        trans_ts_lst.append(TimeSeries.from_times_and_values(times=pd.date_range(start=pd.to_datetime('2013-1-1'),\n",
    "                                                                                 end=cur_ts.start_time()-timedelta(days=1),freq='D'),values=np.zeros(missing_days)).append(cur_ts))\n",
    "    else:\n",
    "        trans_ts_lst.append(cur_ts)\n",
    "\n",
    "# define transaction data cleaning pipeline and clean the data\n",
    "trans_pip = Pipeline([MissingValuesFiller(),Scaler()])\n",
    "trans_ts_lst = trans_pip.fit_transform(trans_ts_lst)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.4 holiday data (static data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "for i in range(len(holiday_df['type'])):\n",
    "    if holiday_df['transferred'][i] == True:\n",
    "        holiday_df['type'][i] = 'non_holiday'\n",
    "holiday_df['type'] = holiday_df['type'].replace(['Transfer','Additional','Bridge'],'Holiday')\n",
    "\n",
    "store_holiday_lst = []\n",
    "for i in range(1,55):\n",
    "    store_holiday = pd.DataFrame()\n",
    "    store_holiday['date'] = holiday_df['date']\n",
    "    store_holiday['earthquake'] = holiday_df['description'].str.contains('Terremoto').astype(int)\n",
    "    store_holiday['workday'] = (holiday_df['type']=='Work Day').astype(int)\n",
    "    store_holiday['worldcup'] = holiday_df['description'].str.contains('futbol').astype(int)\n",
    "    store_holiday['local_holiday'] = ((holiday_df['type']=='Holiday') & (holiday_df['locale']=='Local') & (holiday_df['locale_name']==stores_df['city'][i-1])).astype(int)\n",
    "    store_holiday['regional_holiday'] = ((holiday_df['type']=='Holiday') & (holiday_df['locale']=='Regional') & (holiday_df['locale_name']==stores_df['state'][i-1])).astype(int)\n",
    "    store_holiday['national_holiday'] = ((holiday_df['type']=='Holiday') & (holiday_df['locale']=='National')).astype(int)\n",
    "    store_holiday['newyear'] = ((holiday_df['type']=='Holiday') & (holiday_df['description'].str.contains('Navidad'))).astype(int)\n",
    "    store_holiday['black_friday'] = (holiday_df['description'].str.contains('Black Friday') | holiday_df['description'].str.contains('Cyber Monday')).astype(int)\n",
    "    store_holiday['other_event'] = ((holiday_df['type']=='Event') & ~(store_holiday['worldcup'] | store_holiday['black_friday'] | store_holiday['earthquake'])).astype(int)\n",
    "\n",
    "    store_holiday = store_holiday.loc[(store_holiday==1).any(axis=1)].groupby('date').agg('max').reset_index()\n",
    "    holiday_store_ts = TimeSeries.from_dataframe(store_holiday,time_col='date',fill_missing_dates=True,freq='D',fillna_value=0).slice(pd.to_datetime('2013-1-1'),pd.to_datetime('2017-8-31'))\n",
    "    store_holiday_lst.append(holiday_store_ts)\n",
    "\n",
    "# define holiday data pipeline\n",
    "holiday_pip = Pipeline([MissingValuesFiller()])\n",
    "store_holiday_lst = holiday_pip.fit_transform(store_holiday_lst)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.5 promotion data (past and future data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "promotion_df = pd.concat([train_df,test_df])\n",
    "promotion_ts_lst = TimeSeries.from_group_dataframe(promotion_df,time_col='date',group_cols=['store_nbr','family'],value_cols='onpromotion',fill_missing_dates=True,freq='D')\n",
    "promotion_dict = {}\n",
    "for ts in promotion_ts_lst:\n",
    "    if ts.static_covariates_values()[0,1] in promotion_dict:\n",
    "        promotion_dict[ts.static_covariates_values()[0,1]]['ts'].append(ts)\n",
    "    else:\n",
    "        promotion_dict[ts.static_covariates_values()[0,1]]= {'ts':[ts]}\n",
    "\n",
    "for family in promotion_dict.keys():\n",
    "    # define promotion data cleaning pipeline\n",
    "    promotion_pip = Pipeline([MissingValuesFiller(), Scaler()])\n",
    "    promotion_dict[family]['ts'] = promotion_pip.fit_transform(promotion_dict[family]['ts'])\n",
    "    promotion_dict[family]['pipe'] = promotion_pip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 feature extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "# define moving average windows\n",
    "window_7 = MovingAverage(window=7)\n",
    "window_14 = MovingAverage(window=14)\n",
    "window_28 = MovingAverage(window=28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.1 oil feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "oil_ma_7 = window_7.filter(oil_ts)\n",
    "oil_ma_7 = oil_ma_7.with_columns_renamed(col_names=oil_ma_7.columns, col_names_new=\"oil_ma_7\")\n",
    "oil_ma_28 = window_28.filter(oil_ts)\n",
    "oil_ma_28 = oil_ma_28.with_columns_renamed(col_names=oil_ma_28.columns, col_names_new=\"oil_ma_28\")\n",
    "oil_ma = oil_ma_7.stack(oil_ma_28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.2 sales feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "sales_feature_dict = {}\n",
    "for family in families_dict.keys():\n",
    "    sales_feature_arr = []\n",
    "    for sales_ts in families_dict[family]['ts']:\n",
    "        sales_ma_7 = TimeSeries.from_series(window_7.filter(sales_ts).pd_series())\n",
    "        sales_ma_7 = sales_ma_7.with_columns_renamed(col_names=sales_ma_7.columns, col_names_new=\"sales_ma_7\")\n",
    "        sales_ma_14 = TimeSeries.from_series(window_14.filter(sales_ts).pd_series())\n",
    "        sales_ma_14 = sales_ma_14.with_columns_renamed(col_names=sales_ma_14.columns, col_names_new=\"sales_ma_14\")\n",
    "        sales_ma_28 = TimeSeries.from_series(window_28.filter(sales_ts).pd_series())\n",
    "        sales_ma_28 = sales_ma_28.with_columns_renamed(col_names=sales_ma_28.columns, col_names_new=\"sales_ma_28\")\n",
    "        sales_feature_arr.append(sales_ma_7.stack(sales_ma_14).stack(sales_ma_28))\n",
    "    sales_feature_dict[family] = sales_feature_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.3 transaction feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "transactions_features = []\n",
    "for tran_ts in trans_ts_lst:\n",
    "    transaction_ma_7 = window_7.filter(tran_ts)\n",
    "    transaction_ma_7 = transaction_ma_7.with_columns_renamed(col_names=transaction_ma_7.columns, col_names_new=\"transaction_ma_7\")\n",
    "    transaction_ma_14 = window_14.filter(tran_ts)\n",
    "    transaction_ma_14 = transaction_ma_14.with_columns_renamed(col_names=transaction_ma_14.columns, col_names_new=\"transaction_ma_14\")\n",
    "    transaction_ma_28 = window_28.filter(tran_ts)\n",
    "    transaction_ma_28 = transaction_ma_28.with_columns_renamed(col_names=transaction_ma_28.columns, col_names_new=\"transaction_ma_28\")\n",
    "    transaction_ma = tran_ts.with_columns_renamed(col_names=tran_ts.columns, col_names_new=\"transaction\").stack(transaction_ma_7).stack(transaction_ma_14).stack(transaction_ma_28)\n",
    "    transactions_features.append(transaction_ma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.4 promotion feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "promotion_feature_dict = {}\n",
    "for family in promotion_dict.keys():\n",
    "    promotion_feature_arr = []\n",
    "    for promotion_ts in promotion_dict[family]['ts']:\n",
    "        promotion_ma_7 = TimeSeries.from_series(window_7.filter(promotion_ts).pd_series())\n",
    "        promotion_ma_7 = promotion_ma_7.with_columns_renamed(col_names=promotion_ma_7.columns, col_names_new=\"promotion_ma_7\")\n",
    "        promotion_ma_14 = TimeSeries.from_series(window_14.filter(promotion_ts).pd_series())\n",
    "        promotion_ma_14 = promotion_ma_14.with_columns_renamed(col_names=promotion_ma_14.columns, col_names_new=\"promotion_ma_14\")\n",
    "        promotion_ma_28 = TimeSeries.from_series(window_28.filter(promotion_ts).pd_series())\n",
    "        promotion_ma_28 = promotion_ma_28.with_columns_renamed(col_names=promotion_ma_28.columns, col_names_new=\"promotion_ma_28\")\n",
    "        promotion_feature_arr.append(promotion_ts.with_columns_renamed(col_names=promotion_ts.columns, col_names_new=\"promotion\").stack(promotion_ma_7).stack(promotion_ma_14).stack(promotion_ma_28))\n",
    "    promotion_dict[family] = promotion_feature_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.5 time trend feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "linearTrend = TimeSeries.from_times_and_values(times=pd.date_range('2013-1-1','2017-8-31',freq='D'),values=np.arange(len(pd.date_range('2013-1-1','2017-8-31',freq='D'))),columns=[\"linear_trend\"])\n",
    "year = datetime_attribute_timeseries(time_index=pd.date_range('2013-1-1','2017-8-31',freq='D'), attribute=\"year\")\n",
    "month = datetime_attribute_timeseries(time_index=pd.date_range('2013-1-1','2017-8-31',freq='D'), attribute=\"month\")\n",
    "day = datetime_attribute_timeseries(time_index=pd.date_range('2013-1-1','2017-8-31',freq='D'), attribute=\"day\")\n",
    "dayofyear = datetime_attribute_timeseries(time_index=pd.date_range('2013-1-1','2017-8-31',freq='D'), attribute=\"dayofyear\")\n",
    "dayofweek = datetime_attribute_timeseries(time_index=pd.date_range('2013-1-1','2017-8-31',freq='D'), attribute=\"dayofweek\")\n",
    "weekofyear = datetime_attribute_timeseries(time_index=pd.date_range('2013-1-1','2017-8-31',freq='D'), attribute=\"weekofyear\")\n",
    "time_trend_feature = linearTrend.stack(year).stack(month).stack(day).stack(dayofyear).stack(dayofweek).stack(weekofyear)\n",
    "\n",
    "# define time trend pipeline\n",
    "time_trend_pip = Pipeline([Scaler()])\n",
    "time_trend_train, time_trend_pred = time_trend_feature.split_before(pd.Timestamp('20170816'))\n",
    "time_trend_train = time_trend_pip.fit_transform(time_trend_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.6 combine all the features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "store_feature = []\n",
    "\n",
    "for store_nbr in range(1,55):\n",
    "    store_feature.append(store_holiday_lst[store_nbr-1].stack(time_trend_feature).stack(oil_ma).stack(oil_ts))\n",
    "\n",
    "\n",
    "feature_dict = {}\n",
    "for family in promotion_dict.keys():\n",
    "    feature_arr = []\n",
    "    for i in range(54):\n",
    "        feature_arr.append(promotion_dict[family][i].stack(store_feature[i]))\n",
    "    feature_dict[family] = feature_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Model Training & Prediction\n",
    "## 2.1 model training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [02:35<00:00,  4.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error as msle, mean_squared_error as mse\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "LGBM_Models = {}\n",
    "\n",
    "for family in tqdm(families_dict.keys()):\n",
    "    sales_ts_arr = families_dict[family]['ts']\n",
    "    features = feature_dict[family]\n",
    "\n",
    "    LGBM_Model = LightGBMModel(lags = 35,lags_future_covariates = (14,1),lags_past_covariates = [-16,-17,-18,-19,-20,-21,-22],output_chunk_length=1)\n",
    "    LGBM_Model.fit(series=sales_ts_arr,future_covariates=features,past_covariates=transactions_features,verbose=True)\n",
    "    LGBM_Models[family] = LGBM_Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 model prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:08<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_dic = {}\n",
    "pred_df_arr = []\n",
    "for family in tqdm(families_dict):\n",
    "    sales_ts_arr = families_dict[family]['ts']\n",
    "    features = feature_dict[family]\n",
    "\n",
    "    pred = LGBM_Models[family].predict(n=16,series=sales_ts_arr,future_covariates=features,past_covariates=transactions_features)\n",
    "    pred = families_dict[family]['pipe'].inverse_transform(pred,partial=True)\n",
    "    for i in range(54):\n",
    "        tmp_df = pred[i].pd_dataframe().reset_index()\n",
    "        if (families_dict[family]['ts'][i].univariate_values()[-14:]==0).all():\n",
    "            tmp_df['sales'] = [0] * 16\n",
    "        tmp_df['store_nbr'] = [i+1] * 16\n",
    "        tmp_df['family'] = [family] * 16\n",
    "        pred_df_arr.append(tmp_df)\n",
    "pred_df = pd.concat(pred_df_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Making Submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "pred_df = pd.merge(pred_df,test_df,on=['date','store_nbr','family',])\n",
    "pred_df = pred_df.sort_values(by='id')\n",
    "df_sub = pd.read_csv('data/sample_submission.csv', index_col='id')\n",
    "df_sub.sales = pred_df['sales'].values\n",
    "df_sub.to_csv('submission.csv', index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}